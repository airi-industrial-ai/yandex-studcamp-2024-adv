# Adversarial attacks on fault diagnosis systems
A tutorial on Yandex studcamp in Innopolis 2024 

### Description
The tutorial aims to show how to apply adversarial attacks to fault diagnosis systems and how to protect them using the adversarial training technique. As a result, students will see the vulnerability of fault diagnosis systems to adversarial attacks and learn how to protect such systems.

### Target audience and prerequisite knowledge
The target audience is undergraduate computer science students who want to explore the robustness of fault diagnosis systems. I assume that the audience has a basic knowledge of machine learning, probability theory, statistics and Python programming.

[**Open jupyter notebook**](https://colab.research.google.com/github/airi-industrial-ai/yandex-studcamp-2024-adv/blob/main/notebooks/attacks_on_fault_diagnosis.ipynb)

Topics: Tennessee Eastman Process, Fault Diagnosis Systems, Multi-Layer-Perceptron, Adversarial Attacks, Fast Gradient Sign Method, One-step Target Class Method, Adversarial Training. 

### Instructor

_Vitaliy Pozdnyakov_
_junior research scientist, AIRI_

Vitaliy Pozdnyakov has 7 years of experience in industrial companies as a developer of enterprise resource planning systems and 3 years in scientific research of industrial artificial intelligence methods. Research interests: generative models for time series applications, graph neural networks for operational research, self-supervised learning for fault diagnosis, generative models for risk management.
